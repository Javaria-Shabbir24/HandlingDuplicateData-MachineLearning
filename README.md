# Handling Duplicates in Datasets - Machine Learning

## Overview
This project focuses on techniques to handle duplicate records in datasets, a common issue in data preprocessing for machine learning. Proper handling of duplicates is crucial for maintaining data integrity and ensuring accurate model training and evaluation.

## Dataset
The dataset used in this project is `dataset1.xlsx`.

## Steps Involved
1. **Loading the Dataset:**
   - Import necessary libraries.
   - Load the dataset from `dataset1.xlsx` using pandas.

2. **Exploratory Data Analysis :**
   - Perform basic statistical analysis to understand the dataset.

3. **Identifying Duplicates:**
   - Using pandas functions to identify duplicate rows.

4. **Handling Duplicates:**
   - **Removing Duplicates:** Remove all duplicate rows and keep only unique records.

## Tools and Libraries
- **Python:** Programming language used for the implementation.
- **pandas:** For data manipulation and analysis.

